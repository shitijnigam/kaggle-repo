{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nigamshitij/parse-book-reviews-per-book?scriptVersionId=193072392\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-18T11:55:08.028053Z","iopub.execute_input":"2024-08-18T11:55:08.029106Z","iopub.status.idle":"2024-08-18T11:55:08.035752Z","shell.execute_reply.started":"2024-08-18T11:55:08.029068Z","shell.execute_reply":"2024-08-18T11:55:08.034602Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\n# import pandas as pd\nfrom datetime import datetime\nimport time\nimport random\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-08-18T11:55:08.577035Z","iopub.execute_input":"2024-08-18T11:55:08.57746Z","iopub.status.idle":"2024-08-18T11:55:08.583454Z","shell.execute_reply.started":"2024-08-18T11:55:08.577426Z","shell.execute_reply":"2024-08-18T11:55:08.582127Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def remove_boilerplate(text):\n    boilerplate = ['cookie policy', 'privacy policy', 'terms of service', 'all rights reserved', '\\n']\n    for phrase in boilerplate:\n        text = re.sub(r'(?i)' + re.escape(phrase) + r'.*', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-08-18T11:55:09.571542Z","iopub.execute_input":"2024-08-18T11:55:09.571948Z","iopub.status.idle":"2024-08-18T11:55:09.578052Z","shell.execute_reply.started":"2024-08-18T11:55:09.571916Z","shell.execute_reply":"2024-08-18T11:55:09.576897Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def truncate_at_comments(review_text):\n    comment_identifiers = [\n        'Comments', 'Leave a comment', 'Reader comments', \n        'What do you think?', 'Join the discussion'\n    ]\n    \n    lower_text = review_text.lower()\n    for identifier in comment_identifiers:\n        index = lower_text.find(identifier.lower())\n        if index != -1:\n            return review_text[:index].strip()\n    \n    return review_text","metadata":{"execution":{"iopub.status.busy":"2024-08-18T11:55:10.200665Z","iopub.execute_input":"2024-08-18T11:55:10.201045Z","iopub.status.idle":"2024-08-18T11:55:10.207508Z","shell.execute_reply.started":"2024-08-18T11:55:10.201016Z","shell.execute_reply":"2024-08-18T11:55:10.206409Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def remove_comments(review_soup):\n    # Common class names for comment sections\n    comment_classes = ['comment', 'comments-list', 'comments-area', 'comments', 'comment-section', 'user-comments', 'disqus_thread']\n    \n    for class_name in comment_classes:\n        comment_section = review_soup.find('div', class_=class_name)\n        if comment_section:\n            comment_section.decompose()  # This removes the element from the soup\n    \n    return review_soup","metadata":{"execution":{"iopub.status.busy":"2024-08-18T12:02:54.295485Z","iopub.execute_input":"2024-08-18T12:02:54.295929Z","iopub.status.idle":"2024-08-18T12:02:54.303256Z","shell.execute_reply.started":"2024-08-18T12:02:54.295898Z","shell.execute_reply":"2024-08-18T12:02:54.301909Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def search_book_reviews(book_name, author):\n    # Combine book name and author for search query\n    search_query = f\"{book_name} {author} book review -site:goodreads.com -site:amazon.* -site:reddit.com -site:barnesandnoble.com -site:wikipedia.*&start=10\"\n    \n    # Perform Google search\n    url = f\"https://www.google.com/search?q={search_query.replace(' ', '+')}\"\n    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n    print(f\"URL being looked at: {url}\")\n    \n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Extract search results\n    search_results = soup.find_all('div', class_='g')\n    \n    reviews = []\n    \n    for result in search_results:\n        link = result.find('a')\n        if link:\n            review_url = link['href']\n\n            # Skip non-http links and known non-review sites\n            if not review_url.startswith('http') or any(site in review_url for site in ['google.com', 'wikipedia.org']):\n                continue\n            \n            try:\n                # Fetch the review page\n                review_response = requests.get(review_url, headers=headers, timeout=10)\n                review_soup = BeautifulSoup(review_response.text, 'html.parser')\n                \n                # Remove Comments\n                review_soup = remove_comments(review_soup)\n                \n                # Extract review text (this is a simplistic approach and may need refinement)\n                review_paragraphs = review_soup.find_all('main')\n                # review_list_items = review_soup.find_all('li')\n                \n                # Search for relevant text\n                review_text = ' '.join([p.text for p in review_paragraphs if re.search(r'\\b(review|book|read|author|story|character)\\b', p.text, re.IGNORECASE)])\n                \n                # Remove boilerplate\n                review_text = remove_boilerplate(review_text)\n                \n                # Truncate at Comments\n                review_text = truncate_at_comments(review_text)\n                \n                # original\n                # review_text = ' '.join([p.text for p in review_soup.find_all('p')])\n                \n                # Extract date (this is a placeholder, as date formats vary widely)\n                date = review_soup.find('time')\n                review_date = date['datetime'] if date else 'Unknown'\n                \n                reviews.append({\n                    'review_text': review_text[:10000],  # Limit to first 500 (original) characters\n                    'review_date': review_date,\n                    'review_website': review_url\n                })\n                \n            except Exception as e:\n                print(f\"Error processing {review_url}: {str(e)}\")\n            \n            # Be polite to servers\n            time.sleep(random.uniform(1, 3))\n    \n    # Create DataFrame\n    df = pd.DataFrame(reviews)\n    \n    return df\n\n# Example usage\nbook_name = \"Dune Book 1\"\nauthor = \"Frank Herbert\"\n\ndf = search_book_reviews(book_name, author)\n\n# Save to CSV\ndf.to_csv(f\"{book_name.replace(' ', '_')}_reviews.csv\", index=False)\nprint(f\"Reviews saved to {book_name.replace(' ', '_')}_reviews.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-18T12:07:33.885504Z","iopub.execute_input":"2024-08-18T12:07:33.885937Z","iopub.status.idle":"2024-08-18T12:08:01.513832Z","shell.execute_reply.started":"2024-08-18T12:07:33.885905Z","shell.execute_reply":"2024-08-18T12:08:01.512684Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"URL being looked at: https://www.google.com/search?q=Dune+Book+1+Frank+Herbert+book+review+-site:goodreads.com+-site:amazon.*+-site:reddit.com+-site:barnesandnoble.com+-site:wikipedia.*&start=10\nError processing https://www.grimdarkmagazine.com/review-dune-by-frank-herbert/: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nReviews saved to Dune_Book_1_reviews.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T12:08:04.817604Z","iopub.execute_input":"2024-08-18T12:08:04.817999Z","iopub.status.idle":"2024-08-18T12:08:04.831157Z","shell.execute_reply.started":"2024-08-18T12:08:04.81797Z","shell.execute_reply":"2024-08-18T12:08:04.83001Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                         review_text  \\\n0  On the desert planet...  Illustration: Robert ...   \n1                                                      \n2  \\n\\n\\n\\n\\n\\n\\n\\nUnpopular Opinions on a Sci-Fi...   \n3                                                      \n4  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDune by Frank Herb...   \n\n                 review_date  \\\n0                    Unknown   \n1                    Unknown   \n2  2020-10-20T21:33:00+11:00   \n3                    Unknown   \n4                     12 Nov   \n\n                                      review_website  \n0  https://www.theguardian.com/books/2015/jul/03/...  \n1  https://brandeishoot.com/2024/02/09/reviewing-...  \n2  https://ashsinfinitelibrary.wordpress.com/2020...  \n3  https://www.quora.com/Is-the-first-Dune-book-t...  \n4  https://www.louiseslittlelife.com/blog/dune-by...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_text</th>\n      <th>review_date</th>\n      <th>review_website</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>On the desert planet...  Illustration: Robert ...</td>\n      <td>Unknown</td>\n      <td>https://www.theguardian.com/books/2015/jul/03/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>Unknown</td>\n      <td>https://brandeishoot.com/2024/02/09/reviewing-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\n\\n\\n\\n\\n\\n\\n\\nUnpopular Opinions on a Sci-Fi...</td>\n      <td>2020-10-20T21:33:00+11:00</td>\n      <td>https://ashsinfinitelibrary.wordpress.com/2020...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>Unknown</td>\n      <td>https://www.quora.com/Is-the-first-Dune-book-t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDune by Frank Herb...</td>\n      <td>12 Nov</td>\n      <td>https://www.louiseslittlelife.com/blog/dune-by...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"add","metadata":{},"execution_count":null,"outputs":[]}]}