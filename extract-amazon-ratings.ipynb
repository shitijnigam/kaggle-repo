{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9218865,"sourceType":"datasetVersion","datasetId":5562194}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nigamshitij/extract-amazon-ratings?scriptVersionId=193705892\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T09:28:05.670841Z","iopub.execute_input":"2024-08-23T09:28:05.672183Z","iopub.status.idle":"2024-08-23T09:28:05.693251Z","shell.execute_reply.started":"2024-08-23T09:28:05.672124Z","shell.execute_reply":"2024-08-23T09:28:05.691935Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/book-review-samples/goodreads_fantasy.csv\n/kaggle/input/book-review-samples/goodreads_all_genres.csv\n/kaggle/input/book-review-samples/Darth_Plagueis_reviews(4).csv\n/kaggle/input/book-review-samples/Dune_Book_1_reviews.csv\n/kaggle/input/book-review-samples/Dune_Book_1_reviews(4).csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\nimport requests\nfrom bs4 import BeautifulSoup\nimport time\nimport random\nimport os\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:28:05.870746Z","iopub.execute_input":"2024-08-23T09:28:05.871989Z","iopub.status.idle":"2024-08-23T09:28:05.87896Z","shell.execute_reply.started":"2024-08-23T09:28:05.871926Z","shell.execute_reply":"2024-08-23T09:28:05.876871Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_amazon_link(goodreads_url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    }\n    \n    try:\n        # Convert the main book URL to the \"get a copy\" URL\n        book_id = re.search(r'/show/(\\d+)', goodreads_url).group(1)\n        get_copy_url = f\"https://www.goodreads.com/book/{book_id}/get_a_copy\"\n        \n        print(get_copy_url)\n        \n        response = requests.get(get_copy_url, headers=headers)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        \n        # Find the Amazon link\n        amazon_link = soup.find('a', href=lambda href: href and 'amazon.com' in href)\n        \n        if amazon_link:\n            return amazon_link['href']\n        else:\n            print(f\"No Amazon link found for {goodreads_url}\")\n            return None\n    \n    except Exception as e:\n        print(f\"Error fetching Amazon link for {goodreads_url}: {str(e)}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:29:17.031921Z","iopub.execute_input":"2024-08-23T09:29:17.033248Z","iopub.status.idle":"2024-08-23T09:29:17.04235Z","shell.execute_reply.started":"2024-08-23T09:29:17.033197Z","shell.execute_reply":"2024-08-23T09:29:17.040869Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def get_amazon_ratings(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    }\n    \n    try:\n        response = requests.get(url, headers=headers)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        \n        # Find the star rating\n        star_rating = soup.find('span', {'class': 'a-icon-alt'})\n        if star_rating:\n            star_rating = star_rating.text.split(' out of ')[0]\n        else:\n            star_rating = \"N/A\"\n        \n        # Find the total number of ratings\n        total_ratings = soup.find('span', {'id': 'acrCustomerReviewText'})\n        if total_ratings:\n            total_ratings = total_ratings.text.split(' ratings')[0].replace(',', '')\n        else:\n            total_ratings = \"N/A\"\n        \n        return star_rating, total_ratings\n    \n    except Exception as e:\n        print(f\"Error fetching data for {url}: {str(e)}\")\n        return \"N/A\", \"N/A\"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:29:17.251499Z","iopub.execute_input":"2024-08-23T09:29:17.252589Z","iopub.status.idle":"2024-08-23T09:29:17.261671Z","shell.execute_reply.started":"2024-08-23T09:29:17.252538Z","shell.execute_reply":"2024-08-23T09:29:17.26026Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def remove_duplicates(input_file, output_file):\n    seen = set()\n    with open(input_file, 'r', newline='', encoding='utf-8') as infile, \\\n         open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n        \n        reader = csv.DictReader(infile)\n        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n        writer.writeheader()\n        \n        for row in reader:\n            # Create a tuple of values that define uniqueness\n            key = (row['Title'], row['Authors'])\n            if key not in seen:\n                seen.add(key)\n                writer.writerow(row)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:29:17.393924Z","iopub.execute_input":"2024-08-23T09:29:17.394373Z","iopub.status.idle":"2024-08-23T09:29:17.402974Z","shell.execute_reply.started":"2024-08-23T09:29:17.394333Z","shell.execute_reply":"2024-08-23T09:29:17.401685Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def process_csv(input_file, output_file):\n    # First, remove duplicates\n    temp_file = 'temp_no_duplicates.csv'\n    remove_duplicates(input_file, temp_file)\n    \n    with open(temp_file, 'r', newline='', encoding='utf-8') as infile, \\\n         open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n        \n        reader = csv.DictReader(infile)\n        fieldnames = reader.fieldnames + ['Amazon URL', 'Amazon Star Rating', 'Amazon Total Ratings']\n        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n        writer.writeheader()\n        \n        for row in reader:\n            goodreads_url = row['URL']\n            amazon_url = get_amazon_link(goodreads_url)\n            row['Amazon URL'] = amazon_url if amazon_url else \"N/A\"\n            \n            if amazon_url:\n                star_rating, total_ratings = get_amazon_ratings(amazon_url)\n                row['Amazon Star Rating'] = star_rating\n                row['Amazon Total Ratings'] = total_ratings\n            else:\n                row['Amazon Star Rating'] = \"N/A\"\n                row['Amazon Total Ratings'] = \"N/A\"\n            \n            writer.writerow(row)\n            \n            # Add a delay to avoid overwhelming the servers\n            time.sleep(random.uniform(2, 4))\n    \n    # Clean up the temporary file\n    os.remove(temp_file)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:29:17.941959Z","iopub.execute_input":"2024-08-23T09:29:17.942399Z","iopub.status.idle":"2024-08-23T09:29:17.954037Z","shell.execute_reply.started":"2024-08-23T09:29:17.942357Z","shell.execute_reply":"2024-08-23T09:29:17.952624Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/book-review-samples/goodreads_all_genres.csv'","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:29:18.661971Z","iopub.execute_input":"2024-08-23T09:29:18.662437Z","iopub.status.idle":"2024-08-23T09:29:18.668029Z","shell.execute_reply.started":"2024-08-23T09:29:18.662395Z","shell.execute_reply":"2024-08-23T09:29:18.666748Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    input_file = path\n    output_file = 'output_books_with_amazon_ratings.csv'\n    process_csv(input_file, output_file)\n    print(\"Processing complete. Check the output file.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:29:19.133663Z","iopub.execute_input":"2024-08-23T09:29:19.134171Z","iopub.status.idle":"2024-08-23T09:29:30.24812Z","shell.execute_reply.started":"2024-08-23T09:29:19.134119Z","shell.execute_reply":"2024-08-23T09:29:30.246213Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"https://www.goodreads.com/book/625603/get_a_copy\nNo Amazon link found for https://www.goodreads.com/book/show/625603.Horus_Rising\nhttps://www.goodreads.com/book/381817/get_a_copy\nNo Amazon link found for https://www.goodreads.com/book/show/381817.False_Gods\nhttps://www.goodreads.com/book/815091/get_a_copy\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m input_file \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m      3\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_books_with_amazon_ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mprocess_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete. Check the output file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[29], line 16\u001b[0m, in \u001b[0;36mprocess_csv\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     15\u001b[0m     goodreads_url \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m     amazon_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_amazon_link\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoodreads_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmazon URL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m amazon_url \u001b[38;5;28;01mif\u001b[39;00m amazon_url \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amazon_url:\n","Cell \u001b[0;32mIn[26], line 14\u001b[0m, in \u001b[0;36mget_amazon_link\u001b[0;34m(goodreads_url)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_copy_url)\n\u001b[1;32m     13\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(get_copy_url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m---> 14\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Find the Amazon link\u001b[39;00m\n\u001b[1;32m     17\u001b[0m amazon_link \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, href\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m href: href \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamazon.com\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m href)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bs4/__init__.py:328\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m rejections \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    327\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_encoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeclared_html_encoding,\n\u001b[1;32m    329\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontains_replacement_characters) \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    330\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mprepare_markup(\n\u001b[1;32m    331\u001b[0m          markup, from_encoding, exclude_encodings\u001b[38;5;241m=\u001b[39mexclude_encodings)):\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:361\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.prepare_markup\u001b[0;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[1;32m    358\u001b[0m user_encodings \u001b[38;5;241m=\u001b[39m [document_declared_encoding]\n\u001b[1;32m    360\u001b[0m try_encodings \u001b[38;5;241m=\u001b[39m [user_specified_encoding, document_declared_encoding]\n\u001b[0;32m--> 361\u001b[0m dammit \u001b[38;5;241m=\u001b[39m \u001b[43mUnicodeDammit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_definite_encodings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_definite_encodings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_encodings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_encodings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_html\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_encodings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_encodings\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (dammit\u001b[38;5;241m.\u001b[39mmarkup, dammit\u001b[38;5;241m.\u001b[39moriginal_encoding,\n\u001b[1;32m    369\u001b[0m        dammit\u001b[38;5;241m.\u001b[39mdeclared_html_encoding,\n\u001b[1;32m    370\u001b[0m        dammit\u001b[38;5;241m.\u001b[39mcontains_replacement_characters)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bs4/dammit.py:601\u001b[0m, in \u001b[0;36mUnicodeDammit.__init__\u001b[0;34m(self, markup, known_definite_encodings, smart_quotes_to, is_html, exclude_encodings, user_encodings, override_encodings)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mmarkup\n\u001b[1;32m    600\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mencodings:\n\u001b[1;32m    602\u001b[0m     markup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mmarkup\n\u001b[1;32m    603\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_from(encoding)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bs4/dammit.py:442\u001b[0m, in \u001b[0;36mEncodingDetector.encodings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# Use third-party character set detection to guess at the\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# encoding.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding \u001b[38;5;241m=\u001b[39m \u001b[43mchardet_dammit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_usable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding, tried):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bs4/dammit.py:46\u001b[0m, in \u001b[0;36mchardet_dammit\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchardet_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/charset_normalizer/legacy.py:36\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(byte_str, should_rename_legacy, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(byte_str, \u001b[38;5;28mbytearray\u001b[39m):\n\u001b[1;32m     34\u001b[0m     byte_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(byte_str)\n\u001b[0;32m---> 36\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbest()\n\u001b[1;32m     38\u001b[0m encoding \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     39\u001b[0m language \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlanguage \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m r\u001b[38;5;241m.\u001b[39mlanguage \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/charset_normalizer/api.py:406\u001b[0m, in \u001b[0;36mfrom_bytes\u001b[0;34m(sequences, steps, chunk_size, threshold, cp_isolation, cp_exclusion, preemptive_behaviour, explain, language_threshold, enable_fallback)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding_iana \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m md_chunks:\n\u001b[0;32m--> 406\u001b[0m         chunk_languages \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence_ratio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguage_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_languages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_languages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m         cd_ratios\u001b[38;5;241m.\u001b[39mappend(chunk_languages)\n\u001b[1;32m    414\u001b[0m cd_ratios_merged \u001b[38;5;241m=\u001b[39m merge_coherence_ratios(cd_ratios)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/charset_normalizer/cd.py:379\u001b[0m, in \u001b[0;36mcoherence_ratio\u001b[0;34m(decoded_sequence, threshold, lg_inclusion)\u001b[0m\n\u001b[1;32m    374\u001b[0m popular_character_ordered: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c, o \u001b[38;5;129;01min\u001b[39;00m most_common]\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m lg_inclusion_list \u001b[38;5;129;01mor\u001b[39;00m alphabet_languages(\n\u001b[1;32m    377\u001b[0m     popular_character_ordered, ignore_non_latin\n\u001b[1;32m    378\u001b[0m ):\n\u001b[0;32m--> 379\u001b[0m     ratio: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcharacters_popularity_compare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopular_character_ordered\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;241m<\u001b[39m threshold:\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/charset_normalizer/cd.py:205\u001b[0m, in \u001b[0;36mcharacters_popularity_compare\u001b[0;34m(language, ordered_characters)\u001b[0m\n\u001b[1;32m    198\u001b[0m expected_projection_ratio: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    199\u001b[0m     target_language_characters_count \u001b[38;5;241m/\u001b[39m ordered_characters_count\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    201\u001b[0m character_rank_projection: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(character_rank \u001b[38;5;241m*\u001b[39m expected_projection_ratio)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    204\u001b[0m     large_alphabet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(character_rank_projection \u001b[38;5;241m-\u001b[39m character_rank_in_language) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m    206\u001b[0m ):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    210\u001b[0m     large_alphabet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(character_rank_projection \u001b[38;5;241m-\u001b[39m character_rank_in_language)\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;241m<\u001b[39m target_language_characters_count \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    213\u001b[0m ):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}