{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nigamshitij/ml-recap-bag-of-words-nltk?scriptVersionId=180375503\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T07:09:39.828341Z","iopub.execute_input":"2024-05-29T07:09:39.828776Z","iopub.status.idle":"2024-05-29T07:09:41.260191Z","shell.execute_reply.started":"2024-05-29T07:09:39.828741Z","shell.execute_reply":"2024-05-29T07:09:41.258618Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import nltk + download vocab\nimport nltk\nnltk.download()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:10:30.773878Z","iopub.execute_input":"2024-05-29T07:10:30.774328Z","iopub.status.idle":"2024-05-29T07:12:40.375324Z","shell.execute_reply.started":"2024-05-29T07:10:30.77429Z","shell.execute_reply":"2024-05-29T07:12:40.373758Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"NLTK Downloader\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Downloader>  d\n"},{"name":"stdout","text":"\nDownload which package (l=list; x=cancel)?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Identifier>  english\n"},{"name":"stdout","text":"    Error loading english: Package 'english' not found in index\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Downloader>  d\n"},{"name":"stdout","text":"\nDownload which package (l=list; x=cancel)?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Identifier>  l\n"},{"name":"stdout","text":"Packages:\n  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n  [ ] bcp47............... BCP-47 Language Tags\n  [ ] comparative_sentences Comparative Sentence Dataset\n  [ ] dolch............... Dolch Word List\n  [ ] extended_omw........ Extended Open Multilingual WordNet\n  [ ] framenet_v15........ FrameNet 1.5\n  [ ] framenet_v17........ FrameNet 1.7\n  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n                           2015) subset of the Paraphrase Database.\n  [ ] nombank.1.0......... NomBank Corpus 1.0\n  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n  [ ] omw-1.4............. Open Multilingual Wordnet\n  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n                           Evaluation Shared Task\n  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n                           character properties in Perl\n  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n  [ ] wmt15_eval.......... Evaluation data from WMT15\n  [ ] wordnet2021......... Open English Wordnet 2021\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Hit Enter to continue:  \n"},{"name":"stdout","text":"  [ ] wordnet2022......... Open English Wordnet 2022\n  [ ] wordnet31........... Wordnet 3.1\n\nCollections:\n  [P] all-corpora......... All the corpora\n  [P] all-nltk............ All packages available on nltk_data gh-pages\n                           branch\n  [P] all................. All packages\n  [P] book................ Everything used in the NLTK Book\n  [P] popular............. Popular packages\n  [P] tests............... Packages for running tests\n  [ ] third-party......... Third-party data packages\n\n([*] marks installed packages; [P] marks partially installed collections)\n\nDownload which package (l=list; x=cancel)?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Identifier>  all-corpora\n"},{"name":"stdout","text":"    Downloading collection 'all-corpora'\n       | \n       | Downloading package abc to /usr/share/nltk_data...\n       |   Package abc is already up-to-date!\n       | Downloading package alpino to /usr/share/nltk_data...\n       |   Package alpino is already up-to-date!\n       | Downloading package bcp47 to /usr/share/nltk_data...\n       | Downloading package biocreative_ppi to\n       |     /usr/share/nltk_data...\n       |   Package biocreative_ppi is already up-to-date!\n       | Downloading package brown to /usr/share/nltk_data...\n       |   Package brown is already up-to-date!\n       | Downloading package brown_tei to /usr/share/nltk_data...\n       |   Package brown_tei is already up-to-date!\n       | Downloading package cess_cat to /usr/share/nltk_data...\n       |   Package cess_cat is already up-to-date!\n       | Downloading package cess_esp to /usr/share/nltk_data...\n       |   Package cess_esp is already up-to-date!\n       | Downloading package chat80 to /usr/share/nltk_data...\n       |   Package chat80 is already up-to-date!\n       | Downloading package city_database to /usr/share/nltk_data...\n       |   Package city_database is already up-to-date!\n       | Downloading package cmudict to /usr/share/nltk_data...\n       |   Package cmudict is already up-to-date!\n       | Downloading package comparative_sentences to\n       |     /usr/share/nltk_data...\n       |   Unzipping corpora/comparative_sentences.zip.\n       | Downloading package comtrans to /usr/share/nltk_data...\n       |   Package comtrans is already up-to-date!\n       | Downloading package conll2000 to /usr/share/nltk_data...\n       |   Package conll2000 is already up-to-date!\n       | Downloading package conll2002 to /usr/share/nltk_data...\n       |   Package conll2002 is already up-to-date!\n       | Downloading package conll2007 to /usr/share/nltk_data...\n       |   Package conll2007 is already up-to-date!\n       | Downloading package crubadan to /usr/share/nltk_data...\n       |   Package crubadan is already up-to-date!\n       | Downloading package dependency_treebank to\n       |     /usr/share/nltk_data...\n       |   Package dependency_treebank is already up-to-date!\n       | Downloading package dolch to /usr/share/nltk_data...\n       |   Unzipping corpora/dolch.zip.\n       | Downloading package europarl_raw to /usr/share/nltk_data...\n       |   Package europarl_raw is already up-to-date!\n       | Downloading package extended_omw to /usr/share/nltk_data...\n       | Downloading package floresta to /usr/share/nltk_data...\n       |   Package floresta is already up-to-date!\n       | Downloading package framenet_v15 to /usr/share/nltk_data...\n       |   Unzipping corpora/framenet_v15.zip.\n       | Downloading package framenet_v17 to /usr/share/nltk_data...\n       |   Unzipping corpora/framenet_v17.zip.\n       | Downloading package gazetteers to /usr/share/nltk_data...\n       |   Package gazetteers is already up-to-date!\n       | Downloading package genesis to /usr/share/nltk_data...\n       |   Package genesis is already up-to-date!\n       | Downloading package gutenberg to /usr/share/nltk_data...\n       |   Package gutenberg is already up-to-date!\n       | Downloading package ieer to /usr/share/nltk_data...\n       |   Package ieer is already up-to-date!\n       | Downloading package inaugural to /usr/share/nltk_data...\n       |   Package inaugural is already up-to-date!\n       | Downloading package indian to /usr/share/nltk_data...\n       |   Package indian is already up-to-date!\n       | Downloading package jeita to /usr/share/nltk_data...\n       |   Package jeita is already up-to-date!\n       | Downloading package kimmo to /usr/share/nltk_data...\n       |   Package kimmo is already up-to-date!\n       | Downloading package knbc to /usr/share/nltk_data...\n       |   Package knbc is already up-to-date!\n       | Downloading package lin_thesaurus to /usr/share/nltk_data...\n       |   Package lin_thesaurus is already up-to-date!\n       | Downloading package mac_morpho to /usr/share/nltk_data...\n       |   Package mac_morpho is already up-to-date!\n       | Downloading package machado to /usr/share/nltk_data...\n       |   Package machado is already up-to-date!\n       | Downloading package masc_tagged to /usr/share/nltk_data...\n       |   Package masc_tagged is already up-to-date!\n       | Downloading package movie_reviews to /usr/share/nltk_data...\n       |   Package movie_reviews is already up-to-date!\n       | Downloading package mte_teip5 to /usr/share/nltk_data...\n       |   Package mte_teip5 is already up-to-date!\n       | Downloading package names to /usr/share/nltk_data...\n       |   Package names is already up-to-date!\n       | Downloading package nombank.1.0 to /usr/share/nltk_data...\n       | Downloading package nonbreaking_prefixes to\n       |     /usr/share/nltk_data...\n       |   Unzipping corpora/nonbreaking_prefixes.zip.\n       | Downloading package nps_chat to /usr/share/nltk_data...\n       |   Package nps_chat is already up-to-date!\n       | Downloading package omw to /usr/share/nltk_data...\n       |   Package omw is already up-to-date!\n       | Downloading package omw-1.4 to /usr/share/nltk_data...\n       | Downloading package opinion_lexicon to\n       |     /usr/share/nltk_data...\n       |   Package opinion_lexicon is already up-to-date!\n       | Downloading package panlex_swadesh to /usr/share/nltk_data...\n       | Downloading package paradigms to /usr/share/nltk_data...\n       |   Package paradigms is already up-to-date!\n       | Downloading package pe08 to /usr/share/nltk_data...\n       |   Unzipping corpora/pe08.zip.\n       | Downloading package pil to /usr/share/nltk_data...\n       |   Package pil is already up-to-date!\n       | Downloading package pl196x to /usr/share/nltk_data...\n       |   Package pl196x is already up-to-date!\n       | Downloading package ppattach to /usr/share/nltk_data...\n       |   Package ppattach is already up-to-date!\n       | Downloading package problem_reports to\n       |     /usr/share/nltk_data...\n       |   Package problem_reports is already up-to-date!\n       | Downloading package product_reviews_1 to\n       |     /usr/share/nltk_data...\n       |   Package product_reviews_1 is already up-to-date!\n       | Downloading package product_reviews_2 to\n       |     /usr/share/nltk_data...\n       |   Package product_reviews_2 is already up-to-date!\n       | Downloading package propbank to /usr/share/nltk_data...\n       |   Package propbank is already up-to-date!\n       | Downloading package pros_cons to /usr/share/nltk_data...\n       |   Package pros_cons is already up-to-date!\n       | Downloading package ptb to /usr/share/nltk_data...\n       |   Package ptb is already up-to-date!\n       | Downloading package qc to /usr/share/nltk_data...\n       |   Package qc is already up-to-date!\n       | Downloading package reuters to /usr/share/nltk_data...\n       |   Package reuters is already up-to-date!\n       | Downloading package rte to /usr/share/nltk_data...\n       |   Package rte is already up-to-date!\n       | Downloading package semcor to /usr/share/nltk_data...\n       |   Package semcor is already up-to-date!\n       | Downloading package senseval to /usr/share/nltk_data...\n       |   Package senseval is already up-to-date!\n       | Downloading package sentence_polarity to\n       |     /usr/share/nltk_data...\n       |   Package sentence_polarity is already up-to-date!\n       | Downloading package sentiwordnet to /usr/share/nltk_data...\n       |   Package sentiwordnet is already up-to-date!\n       | Downloading package shakespeare to /usr/share/nltk_data...\n       |   Package shakespeare is already up-to-date!\n       | Downloading package sinica_treebank to\n       |     /usr/share/nltk_data...\n       |   Package sinica_treebank is already up-to-date!\n       | Downloading package smultron to /usr/share/nltk_data...\n       |   Package smultron is already up-to-date!\n       | Downloading package state_union to /usr/share/nltk_data...\n       |   Package state_union is already up-to-date!\n       | Downloading package stopwords to /usr/share/nltk_data...\n       |   Package stopwords is already up-to-date!\n       | Downloading package subjectivity to /usr/share/nltk_data...\n       |   Package subjectivity is already up-to-date!\n       | Downloading package swadesh to /usr/share/nltk_data...\n       |   Package swadesh is already up-to-date!\n       | Downloading package switchboard to /usr/share/nltk_data...\n       |   Package switchboard is already up-to-date!\n       | Downloading package timit to /usr/share/nltk_data...\n       |   Package timit is already up-to-date!\n       | Downloading package toolbox to /usr/share/nltk_data...\n       |   Package toolbox is already up-to-date!\n       | Downloading package treebank to /usr/share/nltk_data...\n       |   Package treebank is already up-to-date!\n       | Downloading package twitter_samples to\n       |     /usr/share/nltk_data...\n       |   Package twitter_samples is already up-to-date!\n       | Downloading package udhr to /usr/share/nltk_data...\n       |   Package udhr is already up-to-date!\n       | Downloading package udhr2 to /usr/share/nltk_data...\n       |   Package udhr2 is already up-to-date!\n       | Downloading package unicode_samples to\n       |     /usr/share/nltk_data...\n       |   Package unicode_samples is already up-to-date!\n       | Downloading package universal_treebanks_v20 to\n       |     /usr/share/nltk_data...\n       |   Package universal_treebanks_v20 is already up-to-date!\n       | Downloading package verbnet to /usr/share/nltk_data...\n       |   Package verbnet is already up-to-date!\n       | Downloading package verbnet3 to /usr/share/nltk_data...\n       |   Unzipping corpora/verbnet3.zip.\n       | Downloading package webtext to /usr/share/nltk_data...\n       |   Package webtext is already up-to-date!\n       | Downloading package wordnet to /usr/share/nltk_data...\n       |   Package wordnet is already up-to-date!\n       | Downloading package wordnet2021 to /usr/share/nltk_data...\n       | Downloading package wordnet2022 to /usr/share/nltk_data...\n       |   Unzipping corpora/wordnet2022.zip.\n       | Downloading package wordnet31 to /usr/share/nltk_data...\n       | Downloading package wordnet_ic to /usr/share/nltk_data...\n       |   Package wordnet_ic is already up-to-date!\n       | Downloading package words to /usr/share/nltk_data...\n       |   Package words is already up-to-date!\n       | Downloading package ycoe to /usr/share/nltk_data...\n       |   Package ycoe is already up-to-date!\n       | \n     Done downloading collection all-corpora\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Downloader>  q\n"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# download all corpora\nfrom nltk.corpus import stopwords\nsw = stopwords.words(\"english\")\nprint(sw[0], \" \", sw[2])\nprint(len(sw))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:14:25.091203Z","iopub.execute_input":"2024-05-29T07:14:25.091704Z","iopub.status.idle":"2024-05-29T07:14:25.101306Z","shell.execute_reply.started":"2024-05-29T07:14:25.091667Z","shell.execute_reply":"2024-05-29T07:14:25.099849Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"i   my\n179\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}